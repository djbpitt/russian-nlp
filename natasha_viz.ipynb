{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617120b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natasha in /Applications/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: pymorphy2 in /Applications/anaconda3/lib/python3.9/site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: navec>=0.9.0 in /Applications/anaconda3/lib/python3.9/site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: slovnet>=0.3.0 in /Applications/anaconda3/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in /Applications/anaconda3/lib/python3.9/site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: yargy>=0.14.0 in /Applications/anaconda3/lib/python3.9/site-packages (from natasha) (0.15.0)\n",
      "Requirement already satisfied: razdel>=0.5.0 in /Applications/anaconda3/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: intervaltree>=3 in /Applications/anaconda3/lib/python3.9/site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Applications/anaconda3/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: numpy in /Users/Peter/.local/lib/python3.9/site-packages (from navec>=0.9.0->natasha) (1.22.3)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Applications/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Applications/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Applications/anaconda3/lib/python3.9/site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: navec in /Applications/anaconda3/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in /Users/Peter/.local/lib/python3.9/site-packages (from navec) (1.22.3)\n",
      "Requirement already satisfied: ipymarkup in /Applications/anaconda3/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: intervaltree>=3 in /Applications/anaconda3/lib/python3.9/site-packages (from ipymarkup) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Applications/anaconda3/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
      "Requirement already satisfied: seaborn in /Applications/anaconda3/lib/python3.9/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Applications/anaconda3/lib/python3.9/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /Applications/anaconda3/lib/python3.9/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/Peter/.local/lib/python3.9/site-packages (from seaborn) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /Applications/anaconda3/lib/python3.9/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Applications/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Applications/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Applications/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Applications/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Applications/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: six in /Applications/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Applications/anaconda3/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: geopy in /Applications/anaconda3/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Applications/anaconda3/lib/python3.9/site-packages (from geopy) (1.52)\n",
      "Requirement already satisfied: branca in /Applications/anaconda3/lib/python3.9/site-packages (0.4.2)\n",
      "Requirement already satisfied: jinja2 in /Applications/anaconda3/lib/python3.9/site-packages (from branca) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Applications/anaconda3/lib/python3.9/site-packages (from jinja2->branca) (1.1.1)\n",
      "Requirement already satisfied: jinja2 in /Applications/anaconda3/lib/python3.9/site-packages (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Applications/anaconda3/lib/python3.9/site-packages (from jinja2) (1.1.1)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.9/site-packages (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Applications/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.9/site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/lib/python3.9/site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: folium in /Applications/anaconda3/lib/python3.9/site-packages (0.12.1.post1)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.9/site-packages (from folium) (2.26.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Applications/anaconda3/lib/python3.9/site-packages (from folium) (2.11.3)\n",
      "Requirement already satisfied: numpy in /Users/Peter/.local/lib/python3.9/site-packages (from folium) (1.22.3)\n",
      "Requirement already satisfied: branca>=0.3.0 in /Applications/anaconda3/lib/python3.9/site-packages (from folium) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Applications/anaconda3/lib/python3.9/site-packages (from jinja2>=2.9->folium) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Applications/anaconda3/lib/python3.9/site-packages (from requests->folium) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.9/site-packages (from requests->folium) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.9/site-packages (from requests->folium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/lib/python3.9/site-packages (from requests->folium) (1.26.7)\n",
      "Requirement already satisfied: intervaltree in /Applications/anaconda3/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Applications/anaconda3/lib/python3.9/site-packages (from intervaltree) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha\n",
    "!pip install navec\n",
    "!pip install ipymarkup\n",
    "!pip install seaborn\n",
    "!pip install geopy\n",
    "!pip install branca\n",
    "!pip install jinja2\n",
    "!pip install requests\n",
    "!pip install folium\n",
    "!pip install intervaltree\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fbb394",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'master_marg.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2j/hcx9qgrx2673kjglxzvt92hw0000gn/T/ipykernel_11721/871034217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0maddr_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAddrExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorph_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'master_marg.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'master_marg.txt'"
     ]
    }
   ],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,   \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger, \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "    AddrExtractor,\n",
    "    Doc\n",
    ")\n",
    "from slovnet import Syntax\n",
    "from navec import Navec\n",
    "from razdel import tokenize, sentenize\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "addr_extractor = AddrExtractor(morph_vocab)\n",
    "\n",
    "with open('master_marg.txt') as f:\n",
    "    contents = f.read()\n",
    "    f.close()\n",
    "doc = Doc(contents)\n",
    "# divides doc into tokens and sents, given start and stop properties\n",
    "doc.segment(segmenter)\n",
    "# every token is morphologically tagged, given pos and feats properties\n",
    "doc.tag_morph(morph_tagger)\n",
    "# named entity recognition\n",
    "doc.tag_ner(ner_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a604d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "from collections import (\n",
    "    ChainMap,\n",
    "    Counter,\n",
    "    OrderedDict,\n",
    "    UserDict,\n",
    "    UserList,\n",
    "    UserString,\n",
    "    defaultdict,\n",
    "    deque,\n",
    "    namedtuple\n",
    ")\n",
    "\n",
    "# nouns = []\n",
    "# adjs = []\n",
    "# for token in doc.tokens:\n",
    "#     if token.pos == 'NOUN':\n",
    "#     if token.pos == 'ADJ':\n",
    "#         token.lemmatize(morph_vocab)\n",
    "#         adjs.append(token.lemma)\n",
    "# noun_count = Counter(nouns)\n",
    "# adj_count = Counter(adjs)\n",
    "\n",
    "people = []\n",
    "for span in doc.spans:\n",
    "    if span.type == 'PER':\n",
    "        span.normalize(morph_vocab)\n",
    "        span.extract_fact(names_extractor)\n",
    "        people.append(span.normal)\n",
    "person_count = Counter(people)\n",
    "\n",
    "df = pd.DataFrame(person_count.most_common(), columns = ['person', 'count'])\n",
    "df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201a9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ipymarkup\n",
    "from ipymarkup import *\n",
    "from ipymarkup.palette import *\n",
    "\n",
    "TEAL = Color(\n",
    "    'teal', \n",
    "    background=material('Teal', '50'),\n",
    "    border=material('Teal', '100'),\n",
    "    text=material('Teal', '300'),\n",
    "    line=material('Teal', '200')\n",
    ")\n",
    "\n",
    "PALETTE.add(TEAL)\n",
    "\n",
    "# produces ipymarkup for the doc, focusing only on spans under the NER tagging scheme\n",
    "def getMarkup(doc):\n",
    "    text  = doc.text\n",
    "    spans = []\n",
    "    for i, span in enumerate(doc.spans):\n",
    "        span.normalize(morph_vocab)\n",
    "        span.extract_fact(names_extractor)\n",
    "        spans.append((span.start,span.stop,span.type))\n",
    "    show_span_box_markup(text, spans, palette = palette({'PER':'teal','LOC':'purple', 'ORG':'orange'}))\n",
    "\n",
    "getMarkup(doc)\n",
    "# dir(ipymarkup.palette.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from geopy.geocoders import Nominatim\n",
    "from collections import UserList\n",
    "import sys\n",
    "\n",
    "# Nominatim geocoder for OpenStreetMap data\n",
    "geolocator = Nominatim(user_agent = 'data_viz')\n",
    "\n",
    "# set number of locations to be analyzed (sorted by freq)\n",
    "num_loc = 30\n",
    "\n",
    "locations = []\n",
    "for span in doc.spans:\n",
    "    if span.type == 'LOC':\n",
    "        span.normalize(morph_vocab)\n",
    "        span.extract_fact(addr_extractor)\n",
    "        locations.append(span.normal)\n",
    "loc_count = Counter(locations).most_common(num_loc)\n",
    "# wraps list in order to add more functionality\n",
    "sorted_locations = UserList(loc_count)\n",
    "\n",
    "# @Emma: using loc_count instead of sorted_locations below causes errors - any idea why?\n",
    "\n",
    "addresses = []\n",
    "coordinates = []\n",
    "for k, v in sorted_locations:\n",
    "    # geocode the string value of 'location' from df1\n",
    "    location = geolocator.geocode(k, language = 'ru')\n",
    "    # create tuples and append them to the list\n",
    "    try:\n",
    "        coordinates.append((location.latitude, location.longitude))\n",
    "        addresses.append(location.address)\n",
    "    except:\n",
    "#         pass\n",
    "        coordinates.append((0, 0))\n",
    "        addresses.append(0)\n",
    "\n",
    "df1 = pd.DataFrame(sorted_locations, columns = ['location', 'freq'])\n",
    "df2 = pd.DataFrame(coordinates, columns = ['latitude', 'longitude'])\n",
    "df3 = pd.DataFrame(addresses, columns = ['address'])\n",
    "\n",
    "# joins the two dataframes horizontally by setting axis = 1\n",
    "table = pd.concat([df1, df2, df3], axis=1)\n",
    "table.index = table.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from geopy.geocoders import Nominatim\n",
    "from collections import UserList\n",
    "import sys\n",
    "\n",
    "# Nominatim geocoder for OpenStreetMap data\n",
    "geolocator = Nominatim(user_agent = 'data_viz')\n",
    "\n",
    "# set number of locations to be analyzed (sorted by freq)\n",
    "num_loc = 30\n",
    "\n",
    "locations = []\n",
    "for span in doc.spans:\n",
    "    if span.type == 'LOC':\n",
    "        span.normalize(morph_vocab)\n",
    "        span.extract_fact(addr_extractor)\n",
    "        locations.append(span.normal)\n",
    "loc_count = Counter(locations).most_common(num_loc)\n",
    "# wraps list in order to add more functionality\n",
    "sorted_locations = UserList(loc_count)\n",
    "\n",
    "# @Emma: using loc_count instead of sorted_locations below causes errors - any idea why?\n",
    "\n",
    "addresses = []\n",
    "coordinates = []\n",
    "for k, v in sorted_locations:\n",
    "    # geocode the string value of 'location' from df1\n",
    "    location = geolocator.geocode(k, language = 'ru')\n",
    "    # create tuples and append them to the list\n",
    "    try:\n",
    "        coordinates.append((location.latitude, location.longitude))\n",
    "        addresses.append(location.address)\n",
    "    except:\n",
    "#         pass\n",
    "        coordinates.append((0, 0))\n",
    "        addresses.append(0)\n",
    "\n",
    "df1 = pd.DataFrame(sorted_locations, columns = ['location', 'freq'])\n",
    "df2 = pd.DataFrame(coordinates, columns = ['latitude', 'longitude'])\n",
    "df3 = pd.DataFrame(addresses, columns = ['address'])\n",
    "\n",
    "# joins the two dataframes horizontally by setting axis = 1\n",
    "table = pd.concat([df1, df2, df3], axis=1)\n",
    "table.index = table.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae5ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = table[['location', 'freq', 'latitude', 'longitude', 'address']]\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4004d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = folium.Map(location = [55.750446, 37.617494], zoom_start = 3)\n",
    "\n",
    "table.apply(lambda row:folium.CircleMarker(\n",
    "    location = [row['latitude'], row['longitude']],\n",
    "    radius = [row['freq']],\n",
    "    popup = row['location']\n",
    ").add_to(map1), axis = 1)\n",
    "\n",
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc839fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "map2 = folium.Map(location = [55.750446, 37.617494], zoom_start = 5)\n",
    "\n",
    "# ensures you are providing float inputs\n",
    "table['latitude'] = table['latitude'].astype(float)\n",
    "table['longitude'] = table['longitude'].astype(float)\n",
    "\n",
    "# Filter the DF for rows, then columns\n",
    "# Reducing data size so it runs faster ??\n",
    "heat_df = table[table['freq'] != 0] \n",
    "heat_df = heat_df[['latitude', 'longitude']]\n",
    "heat_df = heat_df.dropna(axis = 0, subset = ['latitude','longitude'])\n",
    "\n",
    "# List comprehension to make out list of lists\n",
    "heat_data = [[row['latitude'], row['longitude']] for index, row in heat_df.iterrows()]\n",
    "HeatMap(heat_data).add_to(map2)\n",
    "\n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6af0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
